{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Records and Data Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOK8TzTmf+BDkt9NMRjlj2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serereuk-tf/Tensorflow-Example/blob/main/Day1/TF_Records_and_Data_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4M7uCNX7jdv"
      },
      "source": [
        "# TF2 데이터셋 끝내기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_-QJ-A232ai"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IZ39og555a9"
      },
      "source": [
        "# CIFAR100 png Version Download\n",
        "\n",
        "원래 CIFAR100 데이터셋은 pickle 형태로 저장되어서 실생활의 예제와 다름.   \n",
        "더 실생활에 적합한 학습을 위해서 이번엔 png 형태로 변환해서 진행해보려고 함.  \n",
        "Torch의 ImageFolder와 같은 비슷한 폴더 형태로 되어 있을 때 연습용 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgdkZ3Vn5lu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395e7c65-8154-46f7-fa9e-9298814f2111"
      },
      "source": [
        "## Thanks to https://github.com/knjcode/cifar2png\n",
        "!pip -qq install cifar2png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for cifar2png (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VsOYyys40ec",
        "outputId": "d978c569-00b0-4a44-b1a9-7f3df29c1a3a"
      },
      "source": [
        "!cifar2png cifar100 '/content/cifar100'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-100-python.tar.gz does not exists.\n",
            "Downloading cifar-100-python.tar.gz\n",
            "165kKB [00:11, 14.9kKB/s]              \n",
            "Saving train images: 100% 50000/50000 [00:19<00:00, 2544.63it/s]\n",
            "Saving test images: 100% 10000/10000 [00:03<00:00, 2585.66it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISu5hijZ68Qy"
      },
      "source": [
        "데이터 구성은 다음과 같음\n",
        "* train  \n",
        "    * apple\n",
        "    * aquarium_fish\n",
        "    * ...\n",
        "* test \n",
        "    * apple\n",
        "    * aquarium_fish\n",
        "    * ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e89JWlet6j10"
      },
      "source": [
        "# 공식 홈페이지에 있는 코드\n",
        "* _bytes_feature : 주로 이미지나 string을 저장하는데 사용. \n",
        "* _float_feature : float값을 저장하는데 사용. \n",
        "* _int64_feature : 주로 int값을 저장하는데 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N33952Zj52MF"
      },
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.train.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs-WaQqL77ln"
      },
      "source": [
        "# 이미 구현된 좋은 클래스를 조금 수정해보자!\n",
        "\n",
        "https://github.com/PacktPublishing/What-s-New-in-TensorFlow-2.0/blob/master/Chapter03/images/create_tfrecords_from_images.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4XWitja6iru"
      },
      "source": [
        "\"\"\" Create tfrecords for image data\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class ImageTFRecordsCreator(object):\n",
        "  \"\"\" Class \"\"\"\n",
        "  def __init__(self, input_folder, num_shards = 1000, PRINT=False):\n",
        "    \"\"\" Constructor\n",
        "      Args:\n",
        "      input_folder (path) : Image Folder (라벨이 각 폴더명으로 분리 되어 있을 경우)\n",
        "      num_shards (int): number of sharded tfrecord\n",
        "    \"\"\"\n",
        "    self.input_folder = input_folder \n",
        "    self.num_shards = num_shards\n",
        "    self.PRINT = PRINT\n",
        "    file_temp = [os.path.join(input_folder +'/train/' + path) \n",
        "                for path in os.listdir(input_folder +'/train/')]\n",
        "    ## Folder Check ##\n",
        "    file_temp = [i for i in file_temp\n",
        "                 if os.path.isdir(i) and '.ipynb' not in i]\n",
        "    self.target_to_idx = {j:i for i, j in enumerate(\n",
        "                              [k.split('/')[-1] for k in file_temp])}\n",
        "    if self.PRINT:\n",
        "        print('# of labels : {}'.format(len(self.target_to_idx)))\n",
        "\n",
        "\n",
        "  def _int64_feature(self, value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    if not isinstance(value, list):\n",
        "      value = [value]\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "  def _bytes_feature(self, value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if not isinstance(value, list):\n",
        "      value = [value]\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "\n",
        "  # Read image file\n",
        "  def _read_image_file(self, filename):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # Read the image file.\n",
        "    with tf.io.gfile.GFile(filename, 'rb') as f:\n",
        "      image = f.read()\n",
        "    d_file = os.path.basename(filename)\n",
        "    label = self.target_to_idx[filename.split('/')[-2]]\n",
        "    return image, label\n",
        "\n",
        "\n",
        "  # Convert sharded data to tfrecord\n",
        "  def _convert_shard_data_to_tfrecord(self, input_files, output_file):\n",
        "    \"\"\" Convert sharded input files to tfrecords\n",
        "    \"\"\"\n",
        "    with tf.io.TFRecordWriter(output_file) as record_writer:\n",
        "      for input_file in input_files:\n",
        "        data, label = self._read_image_file(input_file)\n",
        "        example = tf.train.Example(features=tf.train.Features(\n",
        "            feature={\n",
        "                'image': self._bytes_feature(tf.compat.as_bytes(data)),\n",
        "                'label': self._int64_feature(label)\n",
        "            }))\n",
        "        record_writer.write(example.SerializeToString())\n",
        "\n",
        "\n",
        "  # Convert data to tfrecord\n",
        "  def _convert_data_to_tfrecord(self, input_files, output_dir):\n",
        "    \"\"\" convert input image files to tfrecords\n",
        "      Args:\n",
        "        input_files (list): List of input images to be converted to tfr\n",
        "        output_dir (str): Output folder where created tfr files will be kept\n",
        "      Description:\n",
        "        Shard input_files if they are above threshold and create those many tfr\n",
        "    \"\"\"\n",
        "    num_input_files = len(input_files)\n",
        "    for i in tqdm(range(0, num_input_files, self.num_shards)):\n",
        "      sharded_input_files = input_files[i:i+self.num_shards]\n",
        "      tfr_file_name = os.path.join(output_dir, 'tfr_'+str(i))\n",
        "      self._convert_shard_data_to_tfrecord(sharded_input_files, tfr_file_name)\n",
        "\n",
        "\n",
        "  # Get file names for train, validate and test\n",
        "  def _get_file_names(self, input_folder):\n",
        "    \"\"\" Get file names for train, test and validation\n",
        "    \"\"\"\n",
        "    # Get all the training files\n",
        "    train_file_names = glob.glob(input_folder+'/train/*/*.png')\n",
        "    validation_file_names = glob.glob(input_folder+'/validate/*/*.png')\n",
        "    test_file_names = glob.glob(input_folder+'/test/*/*.png')\n",
        "\n",
        "    file_names = {}\n",
        "    file_names['train'] = train_file_names\n",
        "    file_names['eval'] = validation_file_names\n",
        "    file_names['test'] = test_file_names\n",
        "    if self.PRINT:\n",
        "        print('train : {} val : {} test : {}'.format(len(train_file_names),\n",
        "                                                     len(validation_file_names),\n",
        "                                                     len(test_file_names)))\n",
        "    return file_names\n",
        "\n",
        "\n",
        "  def create_tfrecords(self, input_folder, tfrecords_outdir):\n",
        "    \"\"\" function to generate tfrecords\n",
        "    Creates three sub-folders, train, eval, test and put resp \n",
        "    tfr files\n",
        "    \"\"\"\n",
        "    raw_files = self._get_file_names(input_folder)\n",
        "    for dataset_type in ['train', 'eval', 'test']:\n",
        "      input_files = [fl for fl in raw_files[dataset_type]]\n",
        "      dataset_resp_dir = os.path.join(tfrecords_outdir, dataset_type)\n",
        "      shutil.rmtree(dataset_resp_dir, ignore_errors=True)\n",
        "      os.makedirs(dataset_resp_dir)\n",
        "      self._convert_data_to_tfrecord(input_files, dataset_resp_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxXLGrll6k2e"
      },
      "source": [
        "# TF Records 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFb_2YhtEhdM",
        "outputId": "921ca354-a8b8-4e40-9354-dd53390671ef"
      },
      "source": [
        "input_folder = 'cifar100'\n",
        "tfrecords_outdir = 'tfrecord_cifar100'\n",
        "num_shards = 1000\n",
        "tfr_creator = ImageTFRecordsCreator(input_folder, num_shards, True)\n",
        "tfr_creator.create_tfrecords(input_folder, tfrecords_outdir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# of labels : 100\n",
            "train : 50000 val : 0 test : 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:09<00:00,  5.38it/s]\n",
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 10/10 [00:01<00:00,  5.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW6g4l2F6qnV"
      },
      "source": [
        "# 만든 친구 읽어보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl76dc-TEtvz"
      },
      "source": [
        "train_dataset = tf.data.TFRecordDataset(glob.glob('tfrecord_cifar100/train/tfr_*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KacLV6gk6sm7"
      },
      "source": [
        "for raw_record in train_dataset.take(5):\n",
        "  print(repr(raw_record))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNLfsKZf7-w5"
      },
      "source": [
        "def _parse_function(serialized_item):\n",
        "    parsed_ = tf.io.parse_example(\n",
        "        serialized=serialized_item,\n",
        "        features={\n",
        "            \"image\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            \"label\": tf.io.FixedLenFeature([], dtype=tf.int64)\n",
        "        }\n",
        "    )\n",
        "    return parsed_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFVfgCd8eRL"
      },
      "source": [
        "train_dataset = train_dataset.map(_parse_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6SyZRNU8ivD"
      },
      "source": [
        "for parsed_record in train_dataset.take(1):\n",
        "  image_raw = parsed_record['image'].numpy()\n",
        "  label = parsed_record['label'].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "fEu15wYR9kqN",
        "outputId": "d3e7e0c4-320e-453a-b384-ffca8ba32dc5"
      },
      "source": [
        "import IPython.display as display\n",
        "display.display(display.Image(data=image_raw))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Tarwp-BX92mm",
        "outputId": "6417d317-72f8-4b84-eb39-42ae531d6d7d"
      },
      "source": [
        "sss = {j:i for i,j in tfr_creator.target_to_idx.items()} \n",
        "sss[label]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'camel'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qa18Pe99uJs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}